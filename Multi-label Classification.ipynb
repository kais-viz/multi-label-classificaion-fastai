{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multiclass Classification using FastAi Library\n\nApplying what I learned from Jermey Howard's [lesson 3 of the fastai course](https://course.fast.ai/videos/?lesson=3) to create a multi-label classification model.\n\n\nI will be taking the dataset from [pyimagesearch's blog post](https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/) where we will identify the colour and type of the outfit in the image.\n\nAlso, there is a [tutorial](https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/) on pyimagesearch which helps you build an image dataset by scraping bing\n\nFor this kernel, I will be applying fastai library to classify the colour and article of clothing in an image. Thanks to [pyimagesearch's blog post](https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/) for creating the dataset by scraping the images from bing. If you want to create your own image dataset, I suggest checking out [this tutorial](https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/) from pyimagesearch."},{"metadata":{},"cell_type":"markdown","source":"To get the image dataset, simply click on **File** and then **Add or upload data** from within a kernel you are editing, then paste `https://www.kaggle.com/kaiska/wardrobe` in the search box and click `Add`.\n\n![add dataset](https://i.imgur.com/Tppldjm.png)"},{"metadata":{},"cell_type":"markdown","source":"Every notebook starts with the following three lines; they ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We import all the necessary packages. We are going to work with the [fastai V1 library](http://www.fast.ai/2018/10/02/fastai-ai/) which sits on top of [Pytorch 1.0](https://hackernoon.com/pytorch-1-0-468332ba5163). The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models.\n\nWe will also import [fastai.widgets](https://docs.fast.ai/widgets.image_cleaner.html#Image-Cleaner-Widget) which offer several widgets to support the workflow of a deep learning practitioner. The purpose of the widgets is to help you organize, clean, and prepare your data for your model. Widgets are separated by data type."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.widgets import *\n\nimport os\nimport sys\nimport cv2\nimport shutil  \nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's first copy our dataset to `/kaggle/working/` to be able to apply changes to the dataset without having to change the directory later. This is because the input directory on kaggle is read-only."},{"metadata":{"trusted":true},"cell_type":"code","source":"# copy dataset to working (to enable manipulating the directory)\npath = '/kaggle/input/apparel-dataset/'   \ndest = '/kaggle/working/dataset/'\nshutil.copytree(path, dest, copy_function = shutil.copy)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this dataset, each picture can have multiple labels. If we take a look at the folder names, we see that each folder contains two labels seperated by an underscore."},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/working/dataset/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To put this in a `DataBunch` while using the [data block API](https://docs.fast.ai/data_block.html), we then need to be using ImageList (and not ImageDataBunch). This will make sure the model created has the proper loss function to deal with the multiple classes. Also, the main difference for using `ImageList` over `ImageDataBunch` is that the later has pre-set constrains, while using `ImageList` gives you [more flexibility](https://forums.fast.ai/t/dataset-creation-imagedatabunch-vs-imagelists/45427/2)."},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms()\n\nimg_src = '/kaggle/working/dataset/'\nsrc = (ImageList.from_folder(img_src) #set image folder\n       .split_by_rand_pct(0.2) #set the split of training and validation to 80/20\n       .label_from_folder(label_delim='_')) #get label names from folder and split by underscore\n\ndata = (src.transform(tfms, size=256) #set image size to 256\n        .databunch(num_workers=0).normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(12,9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_02 = partial(accuracy_thresh, thresh=0.2)\nlearn = cnn_learner(data, models.resnet50, metrics=acc_02, model_dir='/kaggle/working/models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('stage-1-rn50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, slice(3e-5, 5e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('stage-2-rn50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('/kaggle/input/multilabel-models/models/stage-2-rn50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()\nlearn.export()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nimport requests\nfrom PIL import Image\n\ndef save_img_url(url):\n    path = '/kaggle/working/test/'\n    if os.path.exists(path +'test.jpg'):\n        os.remove(path +'test.jpg')\n    if not os.path.isdir(path):\n        os.mkdir(path)\n    os.chdir(path)    \n\n    try:\n        ImgRequest = requests.get(url)\n            # Verifying whether the specified URL exist or not\n        if ImgRequest.status_code == requests.codes.ok:\n                    # Opening a file to write bytes from response content\n                    # Storing this onject as an image file on the hard drive\n            img = open(\"test.jpg\",\"wb\")\n            img.write(ImgRequest.content)\n            img.close()\n                    # Opening Inage file using PIL Image\n            img = Image.open(\"test.jpg\")\n#         img.show()\n        else:\n            print(ImgRequest.status_code)\n    except Exception as e:\n        print(str(e))\n    \n# def get_preds(obj):\n#     labels = str(obj[0]).split(';')\n#     tmp_list = []    \n#     x = 0\n#     for i in obj[2]:\n#         if (i > 0.2):\n#             acc= round(i.item(), 3)*100\n#             tmp_list.append({\"label\": labels[x], \"acc\" : acc})\n#             x+=1\n#     return tmp_list\n\ndef get_preds(obj, learn):\n    labels = []\n    for item in learn.data.c2i:\n        labels.append(item)\n\n    predictions = []\n    x=0\n    for item in pred_obj[2]:\n        acc= round(item.item(), 3)*100\n        if acc > 1:\n            predictions.append({labels[x]:acc})\n        x+=1\n    return predictions\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_img_url('https://cdn1.thr.com/sites/default/files/2017/08/conor_mcgregor_suit.jpg')\nimg = open_image('/kaggle/working/test/test.jpg')\nimg.show()\npred_obj = learn.predict(img)\nprint(get_preds(pred_obj, learn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlabels = []\nfor item in learn.data.c2i:\n    labels.append(item)\n\npredictions = []\nx=0\nfor item in pred_obj[2]:\n    acc= round(item.item(), 3)*100\n    if acc > 10:\n        print(acc)\n        predictions.append({labels[x]:acc})\n    x+=1\nreturn predictions\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npredictions\n# sorted(predictions, key = lambda i: i['age']) \n# from operator import itemgetter\n\n# print(sorted(predictions, key=itemgetter('name'), reverse=True))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}